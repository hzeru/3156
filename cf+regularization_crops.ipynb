{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9084d-16e2-46d5-a216-0782636922a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Callable\n",
    "import os\n",
    "import gc\n",
    "import traceback\n",
    "import warnings\n",
    "from pdb import set_trace\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fea95-db7b-4628-b4db-2b3296c1a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(x: np.ndarray) -> float:\n",
    "    \"\"\" Computes the L1 norm \n",
    "\n",
    "        Args:\n",
    "            x: A 1D or 2D column vector \n",
    "\n",
    "        Return:\n",
    "            A float corresponding to the L1 norm\n",
    "    \"\"\"\n",
    "    lms = np.linalg.norm(x, 1)\n",
    "    return lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12410fb9-8f8f-4df8-8226-bd005db2efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_l2_norm(x: np.ndarray) -> float:\n",
    "    \"\"\" Computes the squared L2 norm \n",
    "\n",
    "        Args:\n",
    "            x: A 1D or 2D column vector \n",
    "\n",
    "        Return:\n",
    "            A float corresponding to the squared L2 norm\n",
    "    \"\"\"\n",
    "    ln = np.linalg.norm(x, ord=2)\n",
    "    return ln**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62c0c4-7ee4-4bda-90a3-852c6ca16088",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_df = pd.read_csv(r'C:\\Users\\hanna\\Fall2024\\ITCS3156\\Projects\\crop_yield.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a2caa-0728-421b-853c-a7b9b9578bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082f7f5-453e-4dce-86b2-44830b31f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e21d9-809b-4eec-ad4c-9008249cd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "rng = np.random.RandomState(0)\n",
    "indices = rng.choice(np.arange(len(crop_df)), size=500, replace=False)\n",
    "sns.pairplot(\n",
    "    data=crop_df.iloc[indices],\n",
    "    y_vars='Yield_tons_per_hectare',\n",
    "    x_vars=list(crop_df.drop('Yield_tons_per_hectare',axis=1).columns),\n",
    "    hue=\"Yield_tons_per_hectare\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143787fe-8df2-4821-8e90-63e90736df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_ohe = crop_df\n",
    "categorical_columns = ['Region','Soil_Type','Crop','Fertilizer_Used','Irrigation_Used', 'Weather_Condition']\n",
    "for col in categorical_columns:\n",
    "    col_ohe = pd.get_dummies(crop_df[col], prefix=col)\n",
    "    crops_ohe = pd.concat((crops_ohe, col_ohe), axis=1).drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d1a8b-35db-4b2b-8596-e4ed880ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_features(X: np.ndarray, degree: int) -> np.ndarray:\n",
    "    \"\"\" Compute polynomial features for pass data\n",
    "\n",
    "        Args:\n",
    "            X: Matrix of input data for which polynomial features\n",
    "                will be computed for.\n",
    "\n",
    "            degree: The degree of the polynomial which will be computed.\n",
    "\n",
    "        Return:\n",
    "            A matrix containing the original data and the new polynomial data.\n",
    "    \"\"\"\n",
    "   \n",
    "    X_poly = X.copy()\n",
    "    for i in range(2, degree+1):  \n",
    "        x_stack = X**i\n",
    "        X_poly = np.hstack([X_poly, x_stack]) \n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5021a7d-1df2-4db3-9d7f-2a0601eb0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_valid_test_data(\n",
    "    X: np.ndarray, \n",
    "    y: np.ndarray, \n",
    ") -> Tuple[np.ndarray]:\n",
    "    \"\"\" Randomizes and then splits the data into train, validation, and test sets.\n",
    "\n",
    "        Args:\n",
    "            X: Data given as a 2D matrix\n",
    "\n",
    "            y: Labels given as a vector \n",
    "    \"\"\"\n",
    "    X_trn, y_trn, X_vld, y_vld, X_tst, y_tst= None, None, None, None, None, None\n",
    "    X_trn,X_tst,y_trn, y_tst = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    X_trn, X_vld, y_trn, y_vld = train_test_split(X_trn,y_trn,test_size=0.2, random_state=42)\n",
    "    return X_trn, y_trn, X_vld, y_vld, X_tst, y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cf225-0bf6-468d-b6bf-a863fd8ef71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def get_preprocessed_data(degree: int)  -> Tuple[np.ndarray]:\n",
    "    \"\"\" Gets preprocessed data for training, validation, and testing\n",
    "\n",
    "        Args:\n",
    "            degree: The degree to use when computing polynomial features. \n",
    "        \n",
    "        Return:\n",
    "            A tuple of NumPy arrays where indices 0-1 \n",
    "            contain the training data/targets, indices 2-3\n",
    "            contain the validation data/targets, and 4-5\n",
    "            contain the testing data/targets.\n",
    "    \"\"\"\n",
    "    X = crops_ohe.drop('Yield_tons_per_hectare', axis=1).values\n",
    "    y = crops_ohe['Yield_tons_per_hectare'].values\n",
    "\n",
    "    X_poly  = poly_features(X, degree)\n",
    "    \n",
    "    X_trn, y_trn, X_vld, y_vld, X_tst, y_tst = get_train_valid_test_data(X_poly, y)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_trn)\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_tst = scaler.transform(X_tst)\n",
    "    X_vld = scaler.transform(X_vld)\n",
    "    \n",
    "    bias = np.ones((X_trn.shape[0], 1))  \n",
    "    X_trn= np.hstack([bias, X_trn])\n",
    "    bias = np.ones((X_tst.shape[0], 1))  \n",
    "    X_tst = np.hstack([bias, X_tst])\n",
    "    bias = np.ones((X_vld.shape[0], 1))  \n",
    "    X_vld = np.hstack([bias, X_vld])\n",
    "\n",
    "    return X_trn, y_trn.reshape(-1, 1), X_vld, y_vld.reshape(-1, 1), X_tst, y_tst.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e05cba-2a40-41eb-9f07-f66eba6283a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928b492-5c33-44a0-8618-c022fa835eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeOrdinaryLeastSquares():\n",
    "    \"\"\" Perfroms ordinary least squares regression\n",
    "    \n",
    "        Attributes:\n",
    "\n",
    "            lamb (float): Regularization parameter for controlling\n",
    "                L2 regularization.\n",
    "\n",
    "            w: Vector of weights \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, lamb: float):\n",
    "        self.lamb = lamb\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> object:\n",
    "        \"\"\" Train OLS to learn optimal weights\n",
    "\n",
    "            Args:\n",
    "                X: Training data given as a 2D matrix\n",
    "\n",
    "                y: Training labels given as a 1D vector\n",
    "\n",
    "             Returns:\n",
    "                The class's own object reference. \n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        regularization_matrix = self.lamb * np.eye(n_features)\n",
    "        regularization_matrix[0, 0] = 0 \n",
    "        self.w = np.linalg.inv(X.T @ X + regularization_matrix) @ X.T @ y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Make predictions using learned weights\n",
    "\n",
    "            Args:\n",
    "                X: Testing data given as a 2D matrix\n",
    "\n",
    "            Returns:\n",
    "                A 2D column vector of predictions for each data sample in X\n",
    "        \"\"\"\n",
    "        predictions = X @ self.w\n",
    "        return predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425bce3-3e37-4ced-a64c-716b72ebf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, y_trn, _, _, X_tst, y_tst = get_preprocessed_data(\n",
    "    degree=5\n",
    ")\n",
    "\n",
    "rols = RidgeOrdinaryLeastSquares(lamb = 0.00006)\n",
    "rols.fit(X_trn, y_trn)\n",
    "y_hat_tst = rols.predict(X_tst)\n",
    "test_mse = mse(y_tst, y_hat_tst)\n",
    "print(\"mse: \",test_mse)\n",
    "test_rmse = rmse(y_tst, y_hat_tst)\n",
    "print(\"rmse: \",test_rmse)\n",
    "\n",
    "plt.plot(y_tst, 'ob', label='Targets')\n",
    "plt.plot(y_hat_tst, 'xr', label='Predictions')\n",
    "plt.xlabel(\"Data Sample Index\")\n",
    "plt.ylabel(\"Error in MPa\")\n",
    "plt.title(\"Test Targets vs Predictions\")\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.3, 1.00))\n",
    "plt.show()\n",
    "\n",
    "print(f\"Weights:\\n{rols.w.flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2c0f1-b096-421a-bf1f-7020aa7621f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(\n",
    "    data_len: int, \n",
    "    batch_size: int = 32,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\" Generates mini-batches based on the data indexes\n",
    "        \n",
    "        Args:\n",
    "            data_len: Length of the data or number of data samples \n",
    "                in the data. This is used to generate the indices of\n",
    "                the data.\n",
    "            \n",
    "            batch_size: Size of each mini-batch where the last mini-batch\n",
    "                might be smaller than the rest if the batch_size does not \n",
    "                evenly divide the data length.\n",
    "\n",
    "        Returns:\n",
    "            A list of NumPy array's holding the indices of batches\n",
    "    \"\"\"\n",
    "    indices = np.arange(data_len)\n",
    "    np.random.shuffle(indices)\n",
    "    batches = [indices[i:i+batch_size] for i in range(0, data_len, batch_size)]\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77189ac7-219a-4154-9e43-5a252600b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeLeastMeanSquares():\n",
    "    \"\"\" Performs ridge regression using least mean squares (gradient descent)\n",
    "    \n",
    "        Attributes:\n",
    "\n",
    "            alpha: learning rate or step size\n",
    "\n",
    "            lamb (float): Regularization parameter for controlling\n",
    "                L2 regularization.\n",
    "                \n",
    "            batch_size: Size of mini-batches for mini-batch gradient\n",
    "                descent.\n",
    "            \n",
    "            epochs: Number of epochs to run for mini-batch\n",
    "                gradient descent\n",
    "                \n",
    "            seed: Seed to be used for NumPy's RandomState class\n",
    "                or universal seed np.random.seed() function.\n",
    "\n",
    "            w: 1D vector of weights \n",
    "\n",
    "            trn_error: Stores the training error for each epoch.\n",
    "\n",
    "            vld_error: Stores the validation error for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha: float,\n",
    "        lamb: float, \n",
    "        batch_size: int,\n",
    "        seed: int = 0,\n",
    "        epochs: int = 1,\n",
    "    ):\n",
    "        self.alpha = alpha\n",
    "        self.lamb = lamb\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.w = None\n",
    "        self.trn_error = None\n",
    "        self.vld_error = None\n",
    "    \n",
    "    def fit(\n",
    "         self, X: np.ndarray, \n",
    "         y: np.ndarray, \n",
    "         X_vld: np.ndarray=None, \n",
    "         y_vld: np.ndarray=None\n",
    "     ) -> object:\n",
    "        \"\"\" Train LMS to learn weights\n",
    "\n",
    "            Args:\n",
    "                X: Training data given as a 2D matrix\n",
    "\n",
    "                y: Training labels given as a 2D column vector\n",
    "                \n",
    "            Returns:\n",
    "                The class's own object reference. \n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        self.trn_error = []\n",
    "        self.vld_error = []\n",
    "        self.w = np.random.rand(X.shape[1],1)\n",
    "        self.lamb = np.full(self.w.shape, self.lamb)\n",
    "        self.lamb[0] = 0 \n",
    "        for e in range(self.epochs):\n",
    "            batches = get_batches(len(X), batch_size=self.batch_size)\n",
    "            \n",
    "            for i in batches:\n",
    "                X_batch = X[i]\n",
    "                y_batch = y[i]\n",
    "                preds = self.predict(X[i])\n",
    "                error = preds - y[i]\n",
    "                mean_grad = (np.dot(X_batch.T, error) / len(X_batch)) + self.lamb * self.w\n",
    "                self.w -= mean_grad * self.alpha\n",
    "        \n",
    "            trn_preds = self.predict(X)\n",
    "            trn_error = rmse(y, trn_preds)\n",
    "            self.trn_error.append(trn_error)\n",
    "    \n",
    "            if X_vld is not None and y_vld is not None:\n",
    "                vld_preds = self.predict(X_vld)\n",
    "                vld_error = rmse(y_vld, vld_preds)\n",
    "                self.vld_error.append(vld_error)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Make predictions using learned weights\n",
    "\n",
    "            Args:\n",
    "                X: Testing data given as a 2D matrix\n",
    "\n",
    "            Returns:\n",
    "                A 2D column vector of predictions for each data sample in X\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642e51a-ec81-4795-9b81-c069c9b0bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, y_trn, X_vld, y_vld, X_tst, y_tst = get_preprocessed_data(\n",
    "    degree=4\n",
    ")\n",
    "\n",
    "rlms = RidgeLeastMeanSquares(\n",
    "        lamb=0.000001,\n",
    "        alpha=.099, \n",
    "        batch_size=100, \n",
    "        epochs=6750,\n",
    "        seed=42\n",
    ")\n",
    "rlms.fit(X_trn, y_trn)\n",
    "y_hat_tst = rlms.predict(X_tst)\n",
    "print(f\"Test y_hat shape: {y_hat_tst.shape}\")\n",
    "tst_rmse = rmse(y_tst, y_hat_tst)\n",
    "print(f\"Test RMSE: {tst_rmse}\")\n",
    "\n",
    "adjusted_r2 = 1 - (1 - r2) * ((len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1))\n",
    "print(adjusted_r2)\n",
    "\n",
    "plt.plot(rlms.trn_error, label='train')\n",
    "plt.plot(rlms.vld_error, label='valid')\n",
    "plt.title(\"LMS Learning Curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend(bbox_to_anchor=(1.2, 1.00))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_tst, 'ob', label='Targets')\n",
    "plt.plot(y_hat_tst, 'xr', label='Predictions')\n",
    "plt.xlabel(\"Data Sample Index\")\n",
    "plt.ylabel(\"Error in MPa\")\n",
    "plt.title(\"Test Targets vs Predictions\")\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.3, 1.00))\n",
    "plt.show()\n",
    "\n",
    "print(f\"Weights:\\n{rlms.w.flatten()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5c0c4-169d-43b2-880d-0151d3c0cba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
